{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "hideCode": true,
    "hidePrompt": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, HTML\n",
    "from ipywidgets import *\n",
    "import prettytable\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('pdf', 'png')\n",
    "plt.rcParams['savefig.dpi'] = 75\n",
    "\n",
    "plt.rcParams['figure.autolayout'] = False\n",
    "plt.rcParams['figure.figsize'] = 10, 6\n",
    "plt.rcParams['axes.labelsize'] = 18\n",
    "plt.rcParams['axes.titlesize'] = 20\n",
    "plt.rcParams['font.size'] = 16\n",
    "plt.rcParams['lines.linewidth'] = 2.0\n",
    "plt.rcParams['lines.markersize'] = 8\n",
    "plt.rcParams['legend.fontsize'] = 14\n",
    "\n",
    "plt.rcParams['text.usetex'] = True\n",
    "plt.rcParams['font.family'] = \"serif\"\n",
    "plt.rcParams['font.serif'] = \"cm\"\n",
    "plt.rcParams['text.latex.preamble'] = \"\\usepackage{subdepth}, \\usepackage{type1cm}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VLASIATOR \n",
    "\n",
    "[Vlasiator](http://vlasiator.fmi.fi) is a code that simulates plasma,\n",
    "in particular targeting space weather simulations. It simulates the\n",
    "dynamics of plasma using a hybrid-Vlasov model, where protons are\n",
    "described by their distribution function $f(r,v,t)$ in\n",
    "ordinary ($r$) and velocity ($v$) space, and electrons are a\n",
    "charge-neutralising fluid. This approach neglects electron kinetic\n",
    "effects but retains ion kinetics. The time-evolution of $f(r,v,t)$ is\n",
    "given by Vlasov's equation, which is coupled self-consistently to\n",
    "Maxwell's equations giving the evolution of the electric and magnetic\n",
    "fields E and B.  Vlasiator propagates the distribution function\n",
    "forward in time with a conservative fifth-order accurate\n",
    "Semi-Lagrangian algorithm . This algorithm allows using long time\n",
    "steps even in the presence of strong magnetic fields, as the\n",
    "propagation in velocity space is not limited by the\n",
    "Courant-Friedrichs-Levy (CFL) condition. The field solver is a\n",
    "second-order accurate divergence-free upwind-constrained transport\n",
    "method.\n",
    "\n",
    "Vlasiator uses a Cartesian mesh library in ordinary space,\n",
    "parallelized with the [DCCRG](http://github.com/fmihpc/dccrg)\n",
    "library. Each cell contains the field variables ($B$, $E$), as well as a\n",
    "3D sparse velocity mesh. Empty velocity space cells are neither stored\n",
    "nor propagated, which in a typical case reduces the total number of\n",
    "phase space cells by a factor of at least 100. In large scale\n",
    "simulations there are typically on the order of a few million\n",
    "spatial-cells in ordinary space, with in total 10<sup>12</sup> cells\n",
    "in the full distribution function.\n",
    "\n",
    "The cartesian mesh is parallelized with MPI, and uses the Zoltan\n",
    "library for dynamic load balancing. It relies heavily on user defined\n",
    "MPI datatypes. The code is futhermore threaded. Typically loops over\n",
    "spatial cells have been threaded, but where the fata dependencies\n",
    "demand also other approaches have been used. Finally the Vlasov\n",
    "solver, representing up to 90% of total run-time, is vectorized using\n",
    "an explicit approach based on using the Agner Fogg's [vectorclass](http://www.agner.org/optimize/#vectorclass).\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Porting \n",
    "\n",
    "### Xeon Phi  Knight's Landing\n",
    "\n",
    "The github branch where the neccessary changes were done is visible\n",
    "here LINK.  The main changes were:\n",
    "\n",
    "  * Added the interface to utilize also the Vec16f and Vec8d datatypes in vectorclass.\n",
    "  * Added the correct compiler flags to enable good performance on the KNL\n",
    " \n",
    "The main challenges was that the code was not compatitable with the\n",
    "Intel MPI stack. Using the MPI library, version 16 or 17, lead to\n",
    "crashes very early on. On other MPI libraries the code is, however,\n",
    "very stable. The root cause for this was not identified. By compiling\n",
    "OpenMPI and utilizing that good performance could be achieved on a KNL\n",
    "development platform.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance\n",
    "\n",
    "All performance tests have been done with the Intel Parallel Studio version 17.0.1. The tests have been run on a Ninja KNL test platform with the Intel Xeon Phi Processor 7210, sporting 64 cores running at a base frequency of 1.3 GHz and DDR4-2133 memory.\n",
    "\n",
    "\n",
    "### Test cases \n",
    "\n",
    "To test the performance of the code three test cases have been\n",
    "created, which have different size. Each of them are a very low\n",
    "resolution version of a real space weather simulation, that fits on\n",
    "one node. The \"small\" case uses 1 GB of memory, the \"medium\" case uses 8 GB of memory and the \"large\" case 40 GB of memory.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiler options and vectorization \n",
    "\n",
    "To begin with we tested various compiler flags, but did not see any significant improvement beyond  \n",
    "```\n",
    "-O2  -xMIC-AVX512 -std=c++11 -qopenmp -ansi-alias\n",
    "```\n",
    "\n",
    "Vlasiator uses Agners vectorclass for vectorizing the computationally most intensive parts of the code, namely the vlasov propagation. The C++ template library provides vector datatypes, e.g., Vec16F, which represents 16 single precision floating point numbers. Operations on these are then compiled to vector intrinsics.  To enable the vectorclass to support 512 bit long vectors one needs to further define `` -DMAX_VECTOR_SIZE=512``.\n",
    "\n",
    "Additionally Vlasiator also supports a fallback code path, which relies on the compiler to do all vectorization.\n",
    "\n",
    "In the following table three variants of the codes was compiled, using the fallback code path, VEC8F vectors which map to AVX2 intrinsice and VEC16F vectors which map to AVX512 intrinsics. The measurements are in millions of cell updates per second, and higher is better. These were run with 16 MPI processes, each spawning 16 threads.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "hideCode": false,
    "hidePrompt": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        a Fallback  b VEC8F  c VEC16F\n",
      "small           30       65        80\n",
      "medium          37       87       107\n",
      "large           38       88       109\n"
     ]
    }
   ],
   "source": [
    "print pandas.DataFrame(index=[\"small\", \"medium\" ,\"large\" ], \n",
    "                      data={\n",
    "        'a Fallback': [30, 37 , 38], \n",
    "        'b VEC8F':     [65, 87 , 88], \n",
    "        'c VEC16F':   [80, 107 ,109 ] \n",
    "}) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that the vectorclass fares significantly better than the fallback code path, and that the code sees a good speedup from using AVX512 intrinsics.\n",
    "\n",
    "### Memory allocators\n",
    "\n",
    "Vlasiator does a lot of dynamic memory allocation and deallocation, and performance is affected byt the chosen allocator. Here we compare the default allocator, jemalloc 4.2.1 and tbbmalloc. These tests were run with 16 MPI processes, each spawning 16 threads, and supporting AVX512 using Agner's vectorclass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "hideCode": false,
    "hidePrompt": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        a malloc  b jemalloc  c tbbmalloc\n",
      "small         80          82           85\n",
      "medium       107         107          140\n",
      "large        109         117          147\n"
     ]
    }
   ],
   "source": [
    "print pandas.DataFrame(index=[\"small\", \"medium\" ,\"large\" ], \n",
    "                      data={\n",
    "        'a malloc':      [80, 107 , 109], \n",
    "        'b jemalloc':    [82, 107 , 117], \n",
    "        'c tbbmalloc':   [85, 140 , 147 ] \n",
    "}) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that for small systems all allocators have similar performance, but for larger datasets tbbmalloc is clearly superior on KNL. \n",
    "\n",
    "\n",
    "### Optimal run parameters\n",
    "\n",
    "\n",
    "To investigate optimal balance of threads and MPI processes we run the\n",
    "code with 4 threads per core, 256 threads in total, varying the number\n",
    "of processes. These tests were run with the optimal choices from above, so with AVX512 support using Agner's vectorclass and tbbmalloc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "hideCode": true,
    "hidePrompt": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        01 x 256  02 x 128  04 x 64  08 x 32  16 x 16  32 x 8  64 x 4\n",
      "small         52        61       68       74       85      88      89\n",
      "medium       167       143      144      142      140     133     126\n",
      "large        153       148      151      148      147     143     141\n"
     ]
    }
   ],
   "source": [
    "print pandas.DataFrame(index=[\"small\", \"medium\" ,\"large\" ], \n",
    "                      data={\n",
    "        '01 x 256':   [52, 167 , 153], \n",
    "        '02 x 128':   [61, 143 , 148], \n",
    "        '04 x 64':   [68, 144 , 151 ],\n",
    "        '08 x 32':   [74, 142 , 148 ],\n",
    "        '16 x 16':   [85, 140 , 147 ],\n",
    "        '32 x 8':   [88, 133 , 143 ],\n",
    "        '64 x 4':   [89, 126 , 141 ]\n",
    "}) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance is fairly even, with 1 process and 256 threads being optimal for large cases and 1 process per core being optimal for the small case. For multinode simulations we expect the 1 process per node option to be less than ideal, one reason for its good performance is the lack of MPI overhead for this one node case. In general 16 processes with 16 threads each seems like a good and balanced choice.\n",
    "\n",
    "Furthermore we investigated the effect of hyperthreads, and 4 threads per core was clearly the optimal choice. For medium and large test cases 4 threads per core was almost twice as fast as 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "hideCode": true,
    "hidePrompt": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         1    2    4\n",
      "small   59   81   85\n",
      "medium  75  113  140\n",
      "large   78  119  147\n"
     ]
    }
   ],
   "source": [
    "print pandas.DataFrame(index=[\"small\", \"medium\" ,\"large\" ], \n",
    "                      data={\n",
    "        '4':   [85, 140 , 147 ],\n",
    "        '2':   [81, 113 , 119], \n",
    "        '1':    [59, 75 , 78 ]\n",
    "}) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### MCDRAM utilization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Hide code",
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
